{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "from kaggle.competitions import twosigmanews\n",
    "env = twosigmanews.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(market_train, news_train) = env.get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing steps\n",
    "\n",
    "# Deleting data prior 2009\n",
    "market_train = market_train.loc[market_train['time'].dt.date>=datetime.date(2009,1,1)]\n",
    "news_train = news_train.loc[news_train['time'].dt.date>=datetime.date(2009,1,1)]\n",
    "\n",
    "# Clipping excess close-open difference\n",
    "market_train['c_open_ratio'] = np.abs(market_train['close']/market_train['open'])\n",
    "threshold = 0.5\n",
    "print('In %i lines price increases by 50%% or more in a day' %(market_train['c_open_ratio']>=1.5).sum())\n",
    "print('In %i lines price decreases by 50%% or more in a day' %(market_train['c_open_ratio']<=0.5).sum())\n",
    "\n",
    "\n",
    "market_train = market_train.loc[market_train['c_open_ratio'] < 1.5]\n",
    "market_train = market_train.loc[market_train['c_open_ratio'] > 0.5]\n",
    "market_train = market_train.drop(columns=['c_open_ratio'])\n",
    "\n",
    "# Filling mktres with raw values\n",
    "column_marketres = ['returnsClosePrevMktres1','returnsOpenPrevMktres1','returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\n",
    "column_raw = ['returnsClosePrevRaw1', 'returnsOpenPrevRaw1','returnsClosePrevRaw10', 'returnsOpenPrevRaw10']\n",
    "for i in range(len(column_raw)):\n",
    "    market_train[column_marketres[i]] = market_train[column_marketres[i]].fillna(market_train[column_raw[i]])\n",
    "    \n",
    "# Clipping excess returns\n",
    "column_return = column_marketres + column_raw + ['returnsOpenNextMktres10']\n",
    "orig_len = market_train.shape[0]\n",
    "for column in column_return:\n",
    "    market_train = market_train.loc[market_train[column]>=-2]\n",
    "    market_train = market_train.loc[market_train[column]<=2]\n",
    "new_len = market_train.shape[0]\n",
    "rmv_len = np.abs(orig_len-new_len)\n",
    "print('There were %i lines removed' %rmv_len)\n",
    "\n",
    "\n",
    "# Removing unknown assetname\n",
    "orig_len = market_train.shape[0]\n",
    "market_train = market_train[~market_train['assetCode'].isin(['EBRYY.OB'])]\n",
    "new_len = market_train.shape[0]\n",
    "rmv_len = np.abs(orig_len-new_len)\n",
    "print('There were %i lines removed' %rmv_len)\n",
    "\n",
    "\n",
    "# Function to remove outliers\n",
    "def remove_outliers(data_frame, column_list, low=0.02, high=0.98):\n",
    "    for column in column_list:\n",
    "        this_column = data_frame[column]\n",
    "        quant_df = this_column.quantile([low,high])\n",
    "        low_limit = quant_df[low]\n",
    "        high_limit = quant_df[high]\n",
    "        data_frame[column] = data_frame[column].clip(lower=low_limit, upper=high_limit)\n",
    "    return data_frame\n",
    "\n",
    "\n",
    "\n",
    "# Function to Remove outliers in news\n",
    "columns_outlier = ['takeSequence', 'bodySize', 'sentenceCount', 'wordCount', 'sentimentWordCount', 'firstMentionSentence','noveltyCount12H',\\\n",
    "                  'noveltyCount24H', 'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H', 'volumeCounts24H',\\\n",
    "                  'volumeCounts3D','volumeCounts5D','volumeCounts7D']\n",
    "news_train = remove_outliers(news_train, columns_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_news(news_train):\n",
    "    drop_list = [\n",
    "        'audiences', 'subjects', 'assetName',\n",
    "        'headline'\n",
    "    ]\n",
    "    news_train.drop(drop_list, axis=1, inplace=True)\n",
    "    \n",
    "    # Factorize categorical columns\n",
    "    for col in ['headlineTag', 'provider', 'sourceId']:\n",
    "        news_train[col], uniques = pd.factorize(news_train[col])\n",
    "        del uniques\n",
    "    \n",
    "    # Remove {} and '' from assetCodes column\n",
    "    news_train['assetCodes'] = news_train['assetCodes'].apply(lambda x: x[1:-1].replace(\"'\", \"\"))\n",
    "    return news_train\n",
    "\n",
    "news_train = preprocess_news(news_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def group_news(news_dataframe):\n",
    "    news_dataframe['date'] = news_dataframe.time.dt.date \n",
    "    aggregations = ['mean']\n",
    "    gp = news_dataframe.groupby(['assetCodes', 'date']).agg(aggregations)\n",
    "    gp.columns = pd.Index([\"{}_{}\".format(e[0], e[1]) for e in gp.columns.tolist()])\n",
    "    gp.reset_index(inplace=True)\n",
    "    # Converting to float\n",
    "    float_cols = {c: 'float32' for c in gp.columns if c not in ['assetCodes', 'date']}\n",
    "    return gp.astype(float_cols)\n",
    "\n",
    "news_aggregate = group_news(news_train)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge market and news dataframes\n",
    "market_train['date'] = market_train.time.dt.date\n",
    "df = market_train.merge(news_aggregate, how='left', left_on=['date', 'assetCode'], \n",
    "                            right_on=['date', 'assetCodes'])\n",
    "del market_train, news_aggregate\n",
    "gc.collect()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NA rows\n",
    "df = df.dropna(axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial target created\n",
    "up = df.returnsOpenNextMktres10 >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns not using\n",
    "reqcol = [c for c in df if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'audiences', \n",
    "                                    'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider', \n",
    "                                    'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe',\n",
    "                                    'sourceTimestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[reqcol].values\n",
    "up = up.values\n",
    "r = df.returnsOpenNextMktres10.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "import numpy as np\n",
    "mins = np.min(X, axis=0)\n",
    "maxs = np.max(X, axis=0)\n",
    "rng = maxs - mins\n",
    "X = 1 - ((maxs - X) / rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, up_train, up_test, r_train, r_test = model_selection.train_test_split(X, up, r, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(n_jobs=4,n_estimators=250,max_depth=8,eta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fitting\n",
    "xgb_model.fit(X_train,up_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.score(X_test,up_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Test set\n",
    "dayss = env.get_prediction_days()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the test set for submission\n",
    "n_days = 0\n",
    "prep_time = 0\n",
    "prediction_time = 0\n",
    "packaging_time = 0\n",
    "for (market_obs_df, news_obs_df, predictions_template_df) in (dayss):\n",
    "    n_days +=1\n",
    "    print(n_days,end=' ')\n",
    "    t = time.time()\n",
    "    news_obs_df = preprocess_news(news_obs_df)\n",
    "    news_aggregate = group_news(news_obs_df)\n",
    "    \n",
    "    market_obs_df['date'] = market_obs_df.time.dt.date\n",
    "    df = market_obs_df.merge(news_aggregate, how='left', left_on=['date', 'assetCode'], \n",
    "                            right_on=['date', 'assetCodes'])\n",
    "    del market_obs_df, news_aggregate\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "    df = df[df.assetCode.isin(predictions_template_df.assetCode)]\n",
    "    X_live = df[reqcol].values\n",
    "    X_live = 1 - ((maxs - X_live) / rng)\n",
    "    prep_time += time.time() - t\n",
    "    \n",
    "    t = time.time()\n",
    "    lp = xgb_model.predict_proba(X_live)\n",
    "    prediction_time += time.time() -t\n",
    "    \n",
    "    t = time.time()\n",
    "    confidence = 2* lp[:,1] -1\n",
    "    preds = pd.DataFrame({'assetCode':df['assetCode'],'confidence':confidence})\n",
    "    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n",
    "    env.predict(predictions_template_df)\n",
    "    packaging_time += time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission\n",
    "env.write_submission_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
