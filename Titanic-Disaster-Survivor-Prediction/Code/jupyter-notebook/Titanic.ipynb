{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "The best tuning parameter for regularization in this dataset is:  0.1\n",
      "R-squared metric of the logistic regression model after 5-fold cross validation when tuning parameter =  0.1 is: 0.7847533632286996\n",
      "['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "[0 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 0\n",
      " 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1\n",
      " 1 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1\n",
      " 1]\n",
      "Pclass         0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "PassengerId    0\n",
      "Parch          0\n",
      "Fare           0\n",
      "dtype: int64\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[3.00000000e+00 1.00000000e+00 3.45000000e+01 ... 8.92000000e+02\n",
      "  0.00000000e+00 7.82920000e+00]\n",
      " [3.00000000e+00 0.00000000e+00 4.70000000e+01 ... 8.93000000e+02\n",
      "  0.00000000e+00 7.00000000e+00]\n",
      " [2.00000000e+00 1.00000000e+00 6.20000000e+01 ... 8.94000000e+02\n",
      "  0.00000000e+00 9.68750000e+00]\n",
      " ...\n",
      " [3.00000000e+00 1.00000000e+00 3.85000000e+01 ... 1.30700000e+03\n",
      "  0.00000000e+00 7.25000000e+00]\n",
      " [3.00000000e+00 1.00000000e+00 3.02725904e+01 ... 1.30800000e+03\n",
      "  0.00000000e+00 8.05000000e+00]\n",
      " [3.00000000e+00 1.00000000e+00 3.02725904e+01 ... 1.30900000e+03\n",
      "  1.00000000e+00 2.23583000e+01]]\n",
      "84.3\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "Titanic_DataSet_org= read_csv(\"D:/UPitt/Studies/DA/Project/all/train.csv\")\n",
    "print(Titanic_DataSet_org.isnull().sum())\n",
    "#print(Titanic_DataSet.loc[:, Titanic_DataSet.isna().any()])\n",
    "#Titanic_DataSet_mod= Titanic_DataSet_org[Titanic_DataSet_org['Age'].isnull()==False]\n",
    "Titanic_DataSet_org['Age'].fillna(Titanic_DataSet_org['Age'].mean(), inplace = True)\n",
    "#Titanic_DataSet_mod= Titanic_DataSet_mod[Titanic_DataSet_mod['Embarked'].isnull()==False]\n",
    "#Titanic_DataSet_mod = Titanic_DataSet_mod.reset_index(drop=True)\n",
    "# print(\"T1:\", Titanic_DataSet_mod)\n",
    "\n",
    "# print(\"Cols\", list(Titanic_DataSet_mod))\n",
    "labelencoder = LabelEncoder()\n",
    "# ohe = OneHotEncoder()\n",
    "Titanic_DataSet_org['Sex'] = labelencoder.fit_transform(Titanic_DataSet_org['Sex'])\n",
    "\n",
    "# embarked = Titanic_DataSet_mod['Embarked']\n",
    "\n",
    "# embarked = labelencoder.fit_transform(embarked)\n",
    "\n",
    "# embarked_enc = ohe.fit_transform(embarked.reshape(-1,1)).toarray()\n",
    "\n",
    "# embarked_enc = pd.DataFrame(embarked_enc, columns=labelencoder.classes_)\n",
    "# print(\"11\",embarked_enc.shape)\n",
    "# frames = [Titanic_DataSet_mod, embarked_enc]\n",
    "# print(\"T2:\", Titanic_DataSet_mod)\n",
    "# Titanic_DataSet_mod=pd.concat(frames, axis=1)\n",
    "\n",
    "# Titanic_DataSet_moda= Titanic_DataSet_mod[['PassengerId','Pclass', 'Sex', 'Age', 'SibSp','Parch','Fare']]\n",
    "# Titanic_DataSet_moda\n",
    "# # Titanic_DataSet_moda['C']= embarked_enc.iloc[:, 0]\n",
    "# # Titanic_DataSet_moda['Q']= embarked_enc.iloc[:, 1]\n",
    "# # Titanic_DataSet_moda['S']= embarked_enc.iloc[:, 2]\n",
    "\n",
    "# print(embarked_enc)\n",
    "# print(Titanic_DataSet_mod)\n",
    "\n",
    "#'PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'\n",
    "X= Titanic_DataSet_org[['Pclass', 'Sex', 'Age', 'SibSp', 'PassengerId','Parch','Fare']].values\n",
    "# arr= numpy.isnan(X)\n",
    "# arr1= arr[arr==False]\n",
    "# print(arr1)\n",
    "Y= Titanic_DataSet_org.Survived\n",
    "# X_train, X_test, Y_train, Y_test= train_test_split(X, Y, random_state= 0)\n",
    "# scaler=preprocessing.StandardScaler().fit(X_train)\n",
    "# X_train_transformed=scaler.transform(X_train) \n",
    "# X_test_transformed=scaler.transform(X_test) \n",
    "\n",
    "# RidgeModel = Ridge(alpha=50).fit(X_train_transformed, Y_train)\n",
    "# print(RidgeModel.score(X_test_transformed, Y_test))\n",
    "\n",
    "# LDAmodelFitted = LinearDiscriminantAnalysis().fit(X_train_transformed, Y_train)\n",
    "# print(\"Accuracy of the LDA model is: \", LDAmodelFitted.score(X_test_transformed, Y_test))\n",
    "\n",
    "# QDAmodelFitted = QuadraticDiscriminantAnalysis().fit(X_train_transformed, Y_train)\n",
    "# print(\"Accuracy of the QDA model is: \", QDAmodelFitted.score(X_test_transformed, Y_test))\n",
    "\n",
    "# LogRegModel= LogisticRegression(C=10).fit(X_train_transformed, Y_train)\n",
    "# print(\"R-squared metric of the logistic regression model is: \", LogRegModel.score(X_test_transformed, Y_test))\n",
    "\n",
    "# knn= KNeighborsClassifier(n_neighbors = 5)\n",
    "# knn.fit(X_train_transformed, Y_train)\n",
    "# print(\"R-squared metric of KNN model is: \", knn.score(X_test_transformed, Y_test))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_trainval, X_test, Y_trainval, Y_test= train_test_split(X, Y, random_state= 0)\n",
    "# arr=np.isnan(X_trainval).any()\n",
    "# print(arr)\n",
    "scaler=preprocessing.StandardScaler().fit(X_trainval)\n",
    "X_trainval_transformed=scaler.transform(X_trainval) \n",
    "X_test_transformed=scaler.transform(X_test) \n",
    "num_folds= 20\n",
    "\n",
    "best_score=0\n",
    "for val in [0.01, 0.1, 1, 2, 10, 100]:\n",
    "    LogRegModel= LogisticRegression(C=val)\n",
    "    scores= cross_val_score(LogRegModel, X_trainval_transformed, Y_trainval, cv=num_folds)\n",
    "    score= np.mean(scores)\n",
    "    if(score > best_score):\n",
    "        best_score= score\n",
    "        best_parameter= val\n",
    "\n",
    "FinalLogRegModel= LogisticRegression(C=best_parameter).fit(X_trainval_transformed, Y_trainval) \n",
    "print(\"The best tuning parameter for regularization in this dataset is: \",best_parameter)\n",
    "print(\"R-squared metric of the logistic regression model after 5-fold cross validation when tuning parameter = \",best_parameter,\n",
    "      \"is:\", FinalLogRegModel.score(X_test_transformed, Y_test))\n",
    "\n",
    "# import statsmodels.formula.api as sm\n",
    " \n",
    "# model = sm.Logit(Y_trainval, X_trainval_transformed)\n",
    " \n",
    "# result = model.fit()\n",
    "# print(result.summary())\n",
    "\n",
    "Titanic_DataSet_test = read_csv(\"D:/UPitt/Studies/DA/Project/all/test.csv\")\n",
    "print(list(Titanic_DataSet_test))\n",
    "Titanic_DataSet_test['Sex'] = labelencoder.fit_transform(Titanic_DataSet_test['Sex'])\n",
    "Titanic_DataSet_test['Age'].fillna(Titanic_DataSet_test['Age'].mean(), inplace = True)\n",
    "Titanic_DataSet_test['Fare'].fillna(Titanic_DataSet_test['Fare'].mean(), inplace = True)\n",
    "#display(Titanic_DataSet_test[['Pclass', 'Sex', 'Age', 'SibSp', 'PassengerId']])\n",
    "X_test= Titanic_DataSet_test[['Pclass', 'Sex', 'Age', 'SibSp', 'PassengerId','Parch','Fare']]\n",
    "print(FinalLogRegModel.predict(X_test_transformed))\n",
    "print(X_test.isnull().sum())\n",
    "#Titanic_DataSet_test= Titanic_DataSet_test[Titanic_DataSet_test['Age'].isnull()==False]\n",
    "prediction_test= FinalLogRegModel.predict(X_test.values)\n",
    "print(prediction_test)\n",
    "result= pd.concat([X_test.PassengerId, pd.Series(prediction_test.reshape(len(prediction_test)))], axis=1)\n",
    "# result.reset_index(inplace=True) # Resets the index, makes factor a column\n",
    "# result.drop(\"Factor\",axis=1,inplace=True) # drop factor from axis 1 and make changes permanent by inplace=True\n",
    "result.rename(columns={'PassengerId': 'PassengerId', 0: 'Survived'}, inplace=True)\n",
    "result.to_csv(\"submission_logreg.csv\", index=False)\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # create param grid object \n",
    "# forrest_params = dict(     \n",
    "#     max_depth = [n for n in range(1, 14)],     \n",
    "#     min_samples_split = [n for n in range(2, 11)], \n",
    "#     min_samples_leaf = [n for n in range(1, 5)],     \n",
    "#     n_estimators = [n for n in range(1, 60, 10)],\n",
    "# )\n",
    "\n",
    "# forrest_params2 = dict(     \n",
    "#     max_depth = [n for n in range(1, 102, 1)],     \n",
    "#     min_samples_split = [n for n in range(2, 102, 1)], \n",
    "#     min_samples_leaf = [n for n in range(1, 102, 1)],     \n",
    "#     n_estimators = [n for n in range(1, 102, 1)],\n",
    "# )\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# forestModel= RandomForestClassifier () \n",
    "# forest_cv = GridSearchCV(estimator=forestModel, param_grid=forrest_params2, cv=5) \n",
    "# forest_cv= forest_cv.fit(X_trainval_transformed, Y_trainval)\n",
    "# print(\"Forest\", forest_cv.score(X_test_transformed, Y_test))\n",
    "\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# C = [n for n in range(1, 102, 1)]\n",
    "# Gamma = [n for n in range(1, 102, 1)]\n",
    "\n",
    "# num_folds= 5\n",
    "# best_score=0\n",
    "# for val in C:\n",
    "#     for gam in Gamma:\n",
    "#         SvmModel= SVC(kernel='rbf', gamma=gam, C=val)\n",
    "#         scores= cross_val_score(SvmModel, X_trainval_transformed, Y_trainval, cv=num_folds)\n",
    "#         score= np.mean(scores)\n",
    "#         if(score > best_score):\n",
    "#             best_score= score\n",
    "#             best_regparameter= val\n",
    "#             best_gamma=gam\n",
    "\n",
    "# FinalSvmModel= SVC(kernel='rbf', gamma=best_gamma, C=best_regparameter).fit(X_trainval_transformed, Y_trainval)\n",
    "# print(\"The best tuning parameter for regularization in this dataset is: \", best_regparameter)\n",
    "# print(\"The best RBF parameter Gamma value in this dataset is: \", best_gamma)\n",
    "\n",
    "# print(\"R-squared metric of the SVM model after 5-fold cross validation when tuning parameter = \",best_regparameter,\n",
    "#       \"and gamma = \",best_gamma,\"is:\", FinalSvmModel.score(X_test_transformed, Y_test))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "random_forest.fit(X_trainval_transformed, Y_trainval)\n",
    "print(X_test.values)\n",
    "Y_pred_rf = random_forest.predict(X_test.values)\n",
    "#random_forest.score(X_trainval_transformed, Y_trainval)\n",
    "acc_random_forest = round(random_forest.score(X_test_transformed, Y_test) * 100, 2)\n",
    "print(acc_random_forest)\n",
    "print(Y_pred_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
